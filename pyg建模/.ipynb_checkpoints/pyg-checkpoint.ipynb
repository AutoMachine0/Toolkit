{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一．PyG简介（PyG 1.3.2）\n",
    "1. PyG为用户提供通用的MessagePassing接口，以便对新的研究想法进行快速干净的原型制作。此外，几乎所有近期提出的邻域聚合函数都适用于此接口，其中包括PyG已经集成的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.torch_geometric.data\n",
    "### a.图数据转换\n",
    "<img src=\"pic/PYG1.png\" width=\"350\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 4], x=[3, 1])\n",
      "Data(edge_index=[2, 4], x=[3, 1])\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "两种边的表达方式最终会转化成同一种Ｄata数据结构\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "#无向图表达时，两个节点之间的一条边需要用两个tuple表示\n",
    "\n",
    "#边表达1：\n",
    "#每个list代表一条有向边，list第一元素是起始节点，第二个元素是终止节点\n",
    "edges1 = [[0,1],[1,0],[1,2],[2,1]]\n",
    "edge_index1 = torch.tensor(edges1, dtype = torch.long)#先转化为tensor\n",
    "\n",
    "#边表达2：\n",
    "#两个list，第一个list存储起始节点，第二个list存储终止节点\n",
    "edges2 = [[0, 1, 1, 2], [1, 0, 2, 1]]\n",
    "edge_index2 = torch.tensor(edges2, dtype = torch.long)\n",
    "\n",
    "node_features = [[-1], [0], [1]]\n",
    "x = torch.tensor(node_features, dtype = torch.float)\n",
    "\n",
    "data1 = Data(x=x, edge_index = edge_index1.t().contiguous())#转化为PyG DATA对象\n",
    "data2 = Data(x=x, edge_index = edge_index2)\n",
    "\n",
    "print(data1)\n",
    "print(data2)\n",
    "print(data1.edge_index)\n",
    "print(data2.edge_index)\n",
    "print(\"两种边的表达方式最终会转化成同一种Ｄata数据结构\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.图数据的属性查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看data属性: ['x', 'edge_index']\n",
      "查看节点特征: tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "edge_index found in data\n",
      "x found in data\n",
      "查看节点数: 3\n",
      "查看边数 4\n",
      "查看节点特征维度: 1\n",
      "查看是否包含独立节点: False\n",
      "查看是否包含节点自环: False\n",
      "查看是否为有向图: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata所有方法可以在以下链接查看:\\nhttps://pytorch-geometric.readthedocs.io/en/1.3.2/modules/data.html#torch_geometric.data.Data\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"查看data属性:\",data1.keys)\n",
    "\n",
    "print(\"查看节点特征:\",data1['x'])\n",
    "\n",
    "for key, item in data1:\n",
    "    print(\"{} found in data\".format(key))\n",
    "    \n",
    "'edge_attr' in data1\n",
    " \n",
    "print(\"查看节点数:\",data1.num_nodes)\n",
    "\n",
    "print(\"查看边数\",data1.num_edges)\n",
    "\n",
    "print(\"查看节点特征维度:\", data1.num_node_features)\n",
    "\n",
    "print(\"查看是否包含独立节点:\", data1.contains_isolated_nodes())\n",
    "\n",
    "print(\"查看是否包含节点自环:\", data1.contains_self_loops())\n",
    "\n",
    "print(\"查看是否为有向图:\", data1.is_directed())\n",
    "\n",
    "'''\n",
    "data所有方法可以在以下链接查看:\n",
    "https://pytorch-geometric.readthedocs.io/en/1.3.2/modules/data.html#torch_geometric.data.Data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.torch_geometric.datasets(公共基准数据集)\n",
    "<img src=\"pic/PYG2.png\" width=\"450\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图数据个数: 600\n",
      "数据种类: 6\n",
      "节点特征数: 3\n",
      "第一张图数据信息: Data(edge_index=[2, 168], x=[37, 3], y=[1]) 37个节点，每个节点3维，168/2=84条边，一个图标签\n",
      "训练图数据规模: ENZYMES(540)\n",
      "测试图数据规模: ENZYMES(60)\n",
      "打乱数据集dataset.shuffle(): ENZYMES(600)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root = \"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ENZYMES\", \n",
    "                    name = 'ENZYMES')\n",
    "\n",
    "print(\"图数据个数:\",len(dataset))\n",
    "print(\"数据种类:\",dataset.num_classes)\n",
    "print(\"节点特征数:\",dataset.num_node_features)\n",
    "\n",
    "data = dataset[0]\n",
    "print(\"第一张图数据信息:\",data,\"37个节点，每个节点3维，168/2=84条边，一个图标签\")\n",
    "#图数据分割\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n",
    "print(\"训练图数据规模:\",train_dataset)\n",
    "print(\"测试图数据规模:\",test_dataset)\n",
    "print(\"打乱数据集dataset.shuffle():\",dataset.shuffle())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图数据个数: 1\n",
      "数据种类: 6\n",
      "节点特征维度: 3703\n",
      "图属性: Data(edge_index=[2, 9104], test_mask=[3327], train_mask=[3327], val_mask=[3327], x=[3327, 3703], y=[3327])\n",
      "data.train_mask: tensor([ True,  True,  True,  ..., False, False, False])\n",
      "data.train_mask个数: 120\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root=\"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/Citeseer\", \n",
    "                    name = \"Citeseer\")\n",
    "\n",
    "print(\"图数据个数:\", len(dataset))\n",
    "print(\"数据种类:\",dataset.num_classes)\n",
    "print(\"节点特征维度:\",dataset.num_node_features)\n",
    "data = dataset[0]\n",
    "print(\"图属性:\",data)\n",
    "print(\"data.train_mask:\",data.train_mask)\n",
    "print(\"data.train_mask个数:\",data.train_mask.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Mini-batches\n",
    "### a.torch_geometric.data.DataLoader\n",
    "<img src=\"pic/PYG3.png\" width=\"450\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个batch属性: Batch(batch=[1042], edge_index=[2, 4048], x=[1042, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[988], edge_index=[2, 3914], x=[988, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[893], edge_index=[2, 3536], x=[893, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[907], edge_index=[2, 3550], x=[907, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1079], edge_index=[2, 4142], x=[1079, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[928], edge_index=[2, 3668], x=[928, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1036], edge_index=[2, 3948], x=[1036, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1230], edge_index=[2, 4568], x=[1230, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1125], edge_index=[2, 4306], x=[1125, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1070], edge_index=[2, 4130], x=[1070, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1096], edge_index=[2, 3910], x=[1096, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[953], edge_index=[2, 3694], x=[953, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1035], edge_index=[2, 3830], x=[1035, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1028], edge_index=[2, 3916], x=[1028, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1148], edge_index=[2, 4538], x=[1148, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1040], edge_index=[2, 4044], x=[1040, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1179], edge_index=[2, 3862], x=[1179, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1018], edge_index=[2, 3904], x=[1018, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[785], edge_index=[2, 3056], x=[785, 21], y=[24])\n",
      "一个batch包含的图数据量: 24\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = dataset = TUDataset(root = \"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ENZYMES\", \n",
    "                              name = 'ENZYMES',\n",
    "                              use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size = 32, shuffle=True)\n",
    "#loader = DataLoader(dataset, batch_size = 32)\n",
    "\n",
    "for batch in loader:\n",
    "    print(\"一个batch属性:\",batch)\n",
    "    print(\"一个batch包含的图数据量:\",batch.num_graphs)\n",
    "\n",
    "print(batch.batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.batch的含义：\n",
    "<img src=\"pic/PYG4.png\" width=\"800\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.torch_scatter.scatter_mean\n",
    "<img src=\"pic/PYG5.png\" width=\"800\"/> \n",
    "关于PyTorch Scatter的用法:\n",
    "https://pytorch-scatter.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 21])\n"
     ]
    }
   ],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = dataset = TUDataset(root = \"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ENZYMES\", \n",
    "                              name = 'ENZYMES',\n",
    "                              use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size = 32, shuffle=True)\n",
    "\n",
    "for data in loader:\n",
    "    data\n",
    "#在一个batch中获取每一个图的节点特征矩平均向量，组成一个矩阵\n",
    "x = scatter_mean(data.x, data.batch, dim=0)\n",
    "print(x.size())                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Data Transforms(构建自己的数据集)\n",
    "<img src=\"pic/PYG6.png\" width=\"800\"/> \n",
    "将17000个3D点云图转化为2D图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerry/anaconda3/lib/python3.8/site-packages/torch_geometric/data/dataset.py:89: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you really want to make use of another pre-processing technique, make sure to delete `/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet/processed/processed` first.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D point 数据： Data(category=[1], edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet',\n",
    "                   categories=['Airplane'])\n",
    "\n",
    "print(\"3D point 数据：\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/PYG7.png\" width=\"800\"/> \n",
    "使用KNN算法将3D点云图转化为2D图\n",
    "# 3D图转化为2D图需要第一在下载数据集时就处理，如果是数据集已经处理过，则3D图转2D图失败"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D point 数据 2D 化： Data(category=[1], edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "\n",
    "# 使用KNN算法将3D云图转化为2D图\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet',\n",
    "                   categories=['Airplane'],\n",
    "                  pre_transform = T.KNNGraph(k=6))\n",
    "\n",
    "print(\"3D point 数据 2D 化：\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/PYG8.png\" width=\"800\"/> \n",
    "使用KNN算法将3D点云图转化为2D图，添加随机绕动\n",
    "# 3D图转化为2D图需要第一在下载数据集时就处理，如果是数据集已经处理过，则3D图转2D图失败"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D point 数据 2D 化,并随机化处理节点： Data(category=[1], edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet',\n",
    "                   categories=['Airplane'],\n",
    "                  pre_transform = T.KNNGraph(k=6),\n",
    "                  transform=T.RandomTranslate(0.01))\n",
    "\n",
    "print(\"3D point 数据 2D 化,并随机化处理节点：\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.GCN构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citeseer()\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root=\"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/Citeseer\", \n",
    "                    name = \"Citeseer\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x , data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.01, \n",
    "                             weight_decay=5e-4)\n",
    "# 转换为训练模式\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask],data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 转换为测试模式\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二．构建消息传递网络--针对空间域图卷积网络的设计范式(Message Passing Networks)\n",
    "![deque](pic/PYG9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.计算无向图中节点的度\n",
    "1. 图拓扑结构如下：\n",
    "\n",
    "<img src=\"pic/PYG10.png\" width=\"500\"/> \n",
    "\n",
    "2. degree方法:\n",
    "\n",
    "<img src=\"pic/PYG11.png\" width=\"500\"/> \n",
    "\n",
    "3. add_self_loop方法：\n",
    "\n",
    "<img src=\"pic/PYG12.png\" width=\"500\"/> \n",
    "\n",
    "4. torch.nn.Linear()方法：\n",
    "\n",
    "<img src=\"pic/PYG13.png\" width=\"500\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数节点数: 4\n",
      "原始数边数: 8\n",
      "原始数据: Data(edge_index=[2, 8], x=[4, 3])\n",
      "增加了自环边数据: tensor([[0, 0, 0, 1, 2, 2, 3, 3, 0, 1, 2, 3],\n",
      "        [1, 2, 3, 0, 0, 3, 0, 2, 0, 1, 2, 3]])\n",
      "edge_index_j: tensor([0, 0, 0, 1, 2, 2, 3, 3, 0, 1, 2, 3])\n",
      "edge_index_i: tensor([1, 2, 3, 0, 0, 3, 0, 2, 0, 1, 2, 3])\n",
      "计算增加自环图数据中起始节点边关系列表的度： tensor([4., 2., 3., 3.])\n",
      "计算原始图数据起始节点边关系列表的度： tensor([3., 1., 2., 2.])\n",
      "计算图数据起始节点边关系列表的度:deg: tensor([3., 1., 2., 2.])\n",
      "计算１/sqrt(d_{i}): tensor([0.5774, 1.0000, 0.7071, 0.7071])\n",
      "edge_index_j_: tensor([0, 0, 0, 1, 2, 2, 3, 3])\n",
      "edge_index_i_: tensor([1, 2, 3, 0, 0, 3, 0, 2])\n",
      "deg_inv_sqrt[ edge_index_j_]: tensor([0.5774, 0.5774, 0.5774, 1.0000, 0.7071, 0.7071, 0.7071, 0.7071])\n",
      "deg_inv_sqrt[ edge_index_i_]: tensor([1.0000, 0.7071, 0.7071, 0.5774, 0.5774, 0.7071, 0.5774, 0.7071])\n",
      "GCN_weight: tensor([0.5774, 0.4082, 0.4082, 0.5774, 0.4082, 0.5000, 0.4082, 0.5000])\n",
      "将行向量GCN_weight变为列向量GCN_weight.view(-1,1): tensor([[0.5774],\n",
      "        [0.4082],\n",
      "        [0.4082],\n",
      "        [0.5774],\n",
      "        [0.4082],\n",
      "        [0.5000],\n",
      "        [0.4082],\n",
      "        [0.5000]])\n",
      "x_t.shape: torch.Size([4, 5])\n",
      "线性变换后的node_features_matrix: tensor([[-1.6301, -0.5392,  1.1824,  1.0544, -0.3296],\n",
      "        [-1.0195, -0.7014,  0.2100,  1.4630, -0.9204],\n",
      "        [-1.5818, -0.7182,  0.7679,  1.4987, -0.6619],\n",
      "        [-1.4372, -1.2551, -0.4755,  2.8317, -1.6585]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "有向图edge_index表示:\n",
      " tensor([[1, 2, 3, 2],\n",
      "        [0, 0, 0, 3]])\n",
      "增加自环的有向图edge_index表示:\n",
      " tensor([[1, 2, 3, 2, 0, 1, 2, 3],\n",
      "        [0, 0, 0, 3, 0, 1, 2, 3]])\n",
      "判断data是否时有向图(增加自环操作不会改变data本身的节点边连接关系):\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch_geometric.data import Data\n",
    "#无向图表达时，两个节点之间的一条边需要用两个tuple表示\n",
    "\n",
    "#边表达2：\n",
    "#两个list，第一个list存储源始节点，第二个list存储目标节点\n",
    "edges = [[0, 0, 0, 1, 2, 2, 3, 3], [1, 2, 3, 0, 0, 3, 0, 2]]\n",
    "edge_index = torch.tensor(edges, dtype = torch.long)\n",
    "\n",
    "node_features = [[-1,1,2], [1,1,1], [0,1,2], [3,1,2]]\n",
    "x = torch.tensor(node_features, dtype = torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index = edge_index)\n",
    "\n",
    "print(\"原始数节点数:\",data.num_nodes)\n",
    "print(\"原始数边数:\",data.num_edges)\n",
    "\n",
    "print(\"原始数据:\",data)\n",
    "\n",
    "from torch_geometric.utils import add_self_loops,degree\n",
    "\n",
    "#给图数据的边增加自环边\n",
    "self_loop_edge, _= add_self_loops(data.edge_index, num_nodes=data.num_nodes)\n",
    "\n",
    "print(\"增加了自环边数据:\", self_loop_edge)\n",
    "\n",
    "edge_index_j, edge_index_i = self_loop_edge\n",
    "\n",
    "print(\"edge_index_j:\",edge_index_j)\n",
    "print(\"edge_index_i:\",edge_index_i)\n",
    "\n",
    "print(\"计算增加自环图数据中起始节点边关系列表的度：\", degree(edge_index_j))\n",
    "print(\"计算原始图数据起始节点边关系列表的度：\",degree(data.edge_index[0],\n",
    "                            num_nodes=data.num_nodes))\n",
    "\n",
    "#对节点度进行运算操作：\n",
    "\n",
    "edge_index_j_, edge_index_i_ = data.edge_index\n",
    "\n",
    "# 计算图数据起始节点边关系列表的度\n",
    "deg = degree(edge_index_j_)\n",
    "\n",
    "# 计算１/sqrt(d_{i})\n",
    "deg_inv_sqrt = deg.pow(-0.5)\n",
    "\n",
    "print(\"计算图数据起始节点边关系列表的度:deg:\",deg)\n",
    "print(\"计算１/sqrt(d_{i}):\",deg_inv_sqrt)\n",
    "\n",
    "print(\"edge_index_j_:\", edge_index_j_)\n",
    "print(\"edge_index_i_:\", edge_index_i_)\n",
    "\n",
    "# GCN 邻居节点聚合权重计算\n",
    "GCN_weight = deg_inv_sqrt[ edge_index_j_]*deg_inv_sqrt[ edge_index_i_]\n",
    "print(\"deg_inv_sqrt[ edge_index_j_]:\",deg_inv_sqrt[ edge_index_j_])\n",
    "print(\"deg_inv_sqrt[ edge_index_i_]:\",deg_inv_sqrt[ edge_index_i_])\n",
    "print(\"GCN_weight:\",GCN_weight)\n",
    "print(\"将行向量GCN_weight变为列向量GCN_weight.view(-1,1):\",GCN_weight.view(-1,1))\n",
    "\n",
    "# 构建带学习参数的线性变换\n",
    "input_features = 3 # 节点的特征维度\n",
    "output_features = 5\n",
    "linear_transform = torch.nn.Linear(input_features, output_features)\n",
    "\n",
    "x_t = linear_transform(data.x)\n",
    "\n",
    "print(\"x_t.shape:\",x_t.shape)\n",
    "\n",
    "print(\"线性变换后的node_features_matrix:\",x_t)\n",
    "\n",
    "# 构造有向图\n",
    "s = [1,2,3,2]\n",
    "t = [0,0,0,3]\n",
    "edges = [s,t]\n",
    "edge_index = torch.tensor(edges, dtype = torch.long)\n",
    "\n",
    "node_features = [[-1,1,2], [1,1,1], [0,1,2], [3,1,2]]\n",
    "x = torch.tensor(node_features, dtype = torch.float)\n",
    "data = Data(x=x, edge_index = edge_index)\n",
    "print(\"有向图edge_index表示:\\n\",data.edge_index)\n",
    "# 有向图增加环\n",
    "self_edge_index,_ = add_self_loops(data.edge_index, num_nodes=data.num_nodes)\n",
    "print(\"增加自环的有向图edge_index表示:\\n\",self_edge_index)\n",
    "print(\"判断data是否时有向图(增加自环操作不会改变data本身的节点边连接关系):\\n\",data.is_directed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.使用消息传递网络构建GCN单层网络前向传播过程\n",
    "### MessagePassing类中函数自动调用逻辑链：\n",
    "\n",
    "self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)——>\n",
    "\n",
    "message(self, x_j, edge_index, size)——>\n",
    "\n",
    "update(self, aggr_out)\n",
    "\n",
    "1.　输入的拓扑图结构:\n",
    "<img src=\"pic/PYG10.png\" width=\"500\"/> \n",
    "2. 输入x_features_matrix的维度自动转换： \n",
    "\n",
    "2.1. 经过线性变换后的x,shape=[4, 5]\n",
    "<img src=\"pic/PYG14_1.png\" width=\"1500\"/> \n",
    "<img src=\"pic/PYG14_2.png\" width=\"1000\"/> \n",
    "2.2. 调用self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)——>message(self, x_j, edge_index, size)\n",
    "\n",
    "x_j自动将x从shape[N, out_channels],N表示途中节点数量，对应edge_index起始节点列表节点信息转换为shape[E,out_channels ]，Ｅ表示edge_index中list的长度.\n",
    "\n",
    "2.3.x_j shape:\n",
    "<img src=\"pic/PYG16.png\" width=\"500\"/> \n",
    "2.4.edge_index:\n",
    "<img src=\"pic/PYG15.png\" width=\"1000\"/> \n",
    "2.5.norm.view(-1,1)*x_j:\n",
    "<img src=\"pic/PYG17.png\" width=\"800\"/> \n",
    "## 3.update(self, aggr_out)||super(GCNConv, self).__init__(aggr='add')\n",
    "\n",
    "## PYG按照edge_index_i list(目标节点边索引列表, target node edge index list)对以edge_index_j list(起始节点边索引列表 source node edge index list)扩展的node feature matrix(使用目标节点边索引扩展的节点特征矩阵)进行聚合,得到本次聚合后的节点特征矩阵X.\n",
    "\n",
    "## norm.view(-1,1)*x_j的node_features_matrix基于edge_index_i中目标节点列表indx选择对应norm.view(-1,1)中行向量使用(aggr='add')中选择的add方式进行消息聚合\n",
    "### 3.1.edge_index(蓝色点表示０号节作为目标节点在edge_index中的索引):\n",
    "<img src=\"pic/PYG18.png\" width=\"800\"/> \n",
    "### 3.2.result(蓝色点表示1号节点，2号节点，3号节点0号节作为起始节点对目标节点0在result_features_matrix中的特征向量):\n",
    "<img src=\"pic/PYG19.png\" width=\"800\"/> \n",
    "### 3.3.aggr_out蓝色点表示0号节经过add聚合后的特征向量\n",
    "<img src=\"pic/PYG20.png\" width=\"800\"/> \n",
    "### 3.4.edge_index_j表示起始节点索引列表\n",
    "### 3.5.edge_index_i表示目标节点索引列表\n",
    "### 3.6.x_j表示x以edge_index_j列表索引扩展的特征矩阵  \n",
    "### 3.7.x_i表示x以edge_index_i列表索引扩展的特征矩阵\n",
    "<img src=\"pic/PYG29.png\" width=\"800\"/> \n",
    "<img src=\"pic/PYG10.png\" width=\"500\"/> \n",
    "4. GCN算法：\n",
    "<img src=\"pic/PYG24.png\" width=\"800\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5985,  0.4058, -1.1607, -0.3281,  0.9678],\n",
      "        [ 0.4292,  0.2020, -0.8265, -0.4245,  0.5796],\n",
      "        [ 0.4491,  0.3468, -1.0333, -0.2742,  0.9022],\n",
      "        [ 0.4491,  0.3468, -1.0333, -0.2742,  0.9022]],\n",
      "       grad_fn=<ScatterAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, normalize_embedding=True):\n",
    "        super(GCN, self).__init__(aggr=\"add\")\n",
    "        # 预定义线性变换操作输入输出维度\n",
    "        self.linear_transfomer = torch.nn.Linear(in_channels, out_channels)\n",
    "        \n",
    "        if normalize_embedding:\n",
    "            self.normalize_emb = True\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 给图增加自环\n",
    "        edge_index,_ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # 特征线性变换\n",
    "        x = self.linear_transfomer(x)\n",
    "        # 消息传递,将图信息传递给message模块进行加工\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j, edge_index, size):\n",
    "        edge_index_j, edge_index_i = edge_index\n",
    "        # edge_index_j起始节点边关系列表\n",
    "        # edge_index_i目标节点边关系列表\n",
    "        deg = degree(edge_index_j)\n",
    "        # 求edge_index_j起始节点边关系列表度开根号的倒数.\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        \n",
    "        GCN_weight = deg_inv_sqrt[edge_index_j]*deg_inv_sqrt[edge_index_i]\n",
    "        # 按　edge_index_j　list 中索引号在　deg_inv_sqrt　list　取值构成新　list\n",
    "        \n",
    "        # GCN_weight.view(-1,1)行向量转列向量\n",
    "        GCN_weight = GCN_weight.view(-1,1)\n",
    "        #图中起始节点特征矩阵乘以对应weight后的节点特征表示矩阵，为信息聚合做准备\n",
    "        weight_node = GCN_weight*x_j\n",
    "        \"\"\"\n",
    "        edge_index_j表示初始节点索引列表\n",
    "        x_j表示x以edge_index_j列表索引扩展的特征矩阵\n",
    "        \"\"\"\n",
    "        return weight_node\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # step 4\n",
    "        add_aggr = aggr_out\n",
    "        # aggr_out 是选择super(GraphGCN, self).__init__(aggr=\"add\")定义的\"add\"方法聚合weight_node特征向量.\n",
    "        # step 5\n",
    "\n",
    "        return add_aggr\n",
    "\n",
    "# data\n",
    "# 构图\n",
    "#edges = [[0, 0, 0, 1, 2, 2, 3, 3], [1, 2, 3, 0, 0, 3, 0, 2]]\n",
    "\n",
    "edges = [[0, 0, 0, 1, 2, 2, 3, 3], [1, 2, 3, 0, 0, 3, 0, 2]]\n",
    "edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "node_features = [[-1, 1, 2], [1, 1, 1], [0, 1, 2], [3, 1, 2]]\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "x = data.x\n",
    "edge_index = data.edge_index\n",
    "\n",
    "GraphGCN = GCN(3, 5)\n",
    "\n",
    "x = GraphGCN(x, edge_index)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、GraphSAGE 单层网络前向计算构建 \n",
    "1. GraghSAGE算法原理:\n",
    "<img src=\"pic/PYG23.png\" width=\"800\"/> \n",
    "2. torch.cat:\n",
    "<img src=\"pic/PYG21.png\" width=\"800\"/> \n",
    "<img src=\"pic/PYG22.png\" width=\"500\"/> \n",
    "3. F.normalize(aggr_out,p=2,dim=1)\n",
    "<img src=\"pic/PYG25.png\" width=\"800\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2119, 0.0156, 0.8516, 0.2007, 0.4351],\n",
      "        [0.0346, 0.3485, 0.9075, 0.0000, 0.2321],\n",
      "        [0.0344, 0.1906, 0.8564, 0.0449, 0.4766],\n",
      "        [0.0000, 0.4588, 0.8087, 0.0000, 0.3681]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#GraphSage\n",
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphSage(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, normalize_embedding=True):\n",
    "        super(GraphSage, self).__init__(aggr=\"mean\")\n",
    "         # 预定义线性变换操作输入输出维度\n",
    "        self.aggr_lin = torch.nn.Linear(2*in_channels, out_channels)\n",
    "        if normalize_embedding:\n",
    "            self.normalize_emb = True\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j, edge_index, size):\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # step 4\n",
    "        mean_aggr = aggr_out\n",
    "        # aggr_out 是选择super(GraphGCN, self).__init__(aggr=\"mean)定义的\"mean\"方法聚合后的特征向量.\n",
    "        \n",
    "        # step 5\n",
    "        # 特征拼接（特征增强）\n",
    "        concat_out = torch.cat((x, mean_aggr), 1)  # x, aggr_out shape相同，按行合并\n",
    "        \n",
    "        # self.aggr_lin(concat_out)降维， F.relu()非线性变换\n",
    "        aggr_out = F.relu(self.aggr_lin(concat_out))\n",
    "        # step 7\n",
    "        if self.normalize_emb:\n",
    "            aggr_out = F.normalize(aggr_out, p=2, dim=1)\n",
    "            # p = 2　２范数\n",
    "            # dim = 1,表示此操作是横向进行\n",
    "            # dim =　0,表示此操作时列向进行\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "# data\n",
    "# 构图\n",
    "edges = [[0, 0, 0, 1, 2, 2, 3, 3], [1, 2, 3, 0, 0, 3, 0, 2]]\n",
    "edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "node_features = [[-1, 1, 2], [1, 1, 1], [0, 1, 2], [3, 1, 2]]\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "x = data.x\n",
    "edge_index = data.edge_index\n",
    "\n",
    "conv = GraphSage(3, 5)\n",
    "x = conv(x, edge_index)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、GAT 单层网络单头注意力机制前向计算构建 \n",
    "1. nn.Parameter()：\n",
    "<img src=\"pic/PYG26.png\" width=\"800\"/> \n",
    "2. GAT注意力机制在PYG中的实现：\n",
    "<img src=\"pic/PYG27.png\" width=\"800\"/> \n",
    "3. 单头GAT公式：\n",
    "<img src=\"pic/PYG28.png\" width=\"800\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3735,  0.7449,  0.0608, -0.4438,  1.4067, -1.0382],\n",
      "        [-0.4167,  0.3876, -0.0779, -0.4843,  1.4095, -0.7658],\n",
      "        [-0.4016,  0.7115,  0.0482, -0.5224,  1.5565, -0.9724],\n",
      "        [-0.4016,  0.7115,  0.0482, -0.5224,  1.5565, -0.9724]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops,softmax\n",
    "\n",
    "class GAT(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dropout=0, bias=True,):\n",
    "        super(GAT, self).__init__(aggr='add')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.dropout = dropout\n",
    "        self.lin = torch.nn.Linear(in_channels, self.out_channels)\n",
    "        self.att = torch.nn.Parameter(torch.Tensor(1, self.out_channels*2))\n",
    "        #因为节点特征需要拼接后再乘以节点特征注意力权重向量a,所以节点特征注意力权重向量a的维度为self.out_channel*2\n",
    "\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(self.out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.att)\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        if size is None and torch.is_tensor(x):\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # 原始特征线性变换：\n",
    "        x = self.lin(x)\n",
    "        return self.propagate(edge_index, size=size, x=x)\n",
    "\n",
    "    def message(self, edge_index_j,edge_index_i, x_i, x_j, size_i):\n",
    "\n",
    "        # x_i = x_i.view(-1, 1, self.out_channels)\n",
    "        # x_j = x_j.view(-1, 1, self.out_channels)\n",
    "\n",
    "        alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)\n",
    "        # sum(dim=-1): 按行进求和;\n",
    "        # torch.cat([x_i, x_j], dim=-1): x_i矩阵与x_j矩阵按行拼接;\n",
    "        # torch.cat([x_i, x_j], dim=-1) * self.att: self.att 注意力系数点乘x_i与x_j矩阵拼接后每一行;\n",
    "        # (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1): sum(dim=-1)对shape[12,12]按行求和\n",
    "\n",
    "        alpha = F.leaky_relu(alpha, 0.2)\n",
    "        # 求每行值的激活值\n",
    "\n",
    "        alpha = softmax(alpha, edge_index_i, size_i)\n",
    "        #alpha计算是起始节点到目标节点注意力权重，也是就节点edge_index_j——>节点edge_index_i的注意力权重\n",
    "\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)#self.dropout = 1,没有进行dropout处理\n",
    "        \n",
    "        result = x_j * alpha.view(-1, 1)\n",
    "        # x_j表示按edge_index_j扩展的初始节点特征矩阵\n",
    "\n",
    "        return result\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out: result　以 edge_index_i 节点序号为聚合顺利,按aggr=add的方式进行聚合\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "# data\n",
    "edges = [[0, 0, 0, 1, 2, 2, 3, 3], [1, 2, 3, 0, 0, 3, 0, 2]]\n",
    "edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "node_features = [[-1, 1, 2], [1, 1, 1], [0, 1, 2], [3, 1, 2]]\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "x = data.x\n",
    "edge_index = data.edge_index\n",
    "\n",
    "\n",
    "conv = GAT(3, 6)\n",
    "x = conv(x, edge_index)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、GAT多头注意力机制原理\n",
    "## 核心思想：在单头gat上平行的使用多次独立注意力机制，其中每一次注意力机制的参数独立\n",
    "1. 单层一个神经元神经网络：\n",
    "<img src=\"pic/GAT5.png\" width=\"800\"/> \n",
    "2. GAT论文原理介绍（gat中注意力机制ａ使用的是单层一个神经元神经网络结构）:\n",
    "<img src=\"pic/GAT1.png\" width=\"800\"/> \n",
    "<img src=\"pic/GAT2.png\" width=\"800\"/> \n",
    "<img src=\"pic/GAT3.png\" width=\"800\"/> \n",
    "<img src=\"pic/GAT4.png\" width=\"800\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
